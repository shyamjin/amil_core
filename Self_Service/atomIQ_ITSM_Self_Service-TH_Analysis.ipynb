{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Amily_Path=\"/prjvl01/amily/Self_Service/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Configure Self Service Log\n",
    "logging.basicConfig(filename=Amily_Path+'Logs/self_service.log',\n",
    "                    format='%(asctime)s.%(msecs)03d %(levelname)s %(message)s', \n",
    "                    datefmt='%Y-%m-%d,%H:%M:%S',\n",
    "                    level=logging.DEBUG\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(account, request_id):\n",
    "    read_success=False\n",
    "    \n",
    "    try:\n",
    "        infile_name=\"\".join([Amily_Path,'Archive/Classification/',account,'--',str(request_id),'.txt']) #default path\n",
    "        #print(infile_name)\n",
    "        \n",
    "        account_archive_files=glob.glob(Amily_Path+'Archive/Classification/'+'*'+account+'*.txt')\n",
    "        for path in account_archive_files:\n",
    "            path_req_id=int(path[path.rfind('--')+2:path.rfind('.')])\n",
    "            #print(path_req_id,'--->',int(request_id),'\\t',path_req_id==int(request_id))\n",
    "            if path_req_id==int(request_id):\n",
    "                infile_name=path\n",
    "                #print('F--->',infile_name)\n",
    "\n",
    "        eval_flow_matrix=pd.read_csv(infile_name)\n",
    "    except:\n",
    "        print(infile_name,' Was not found')\n",
    "        return None, None, None, read_success \n",
    "    \n",
    "    cou=1\n",
    "    flow_str = \"\"\n",
    "    flow_dict={}\n",
    "    for flow_name in eval_flow_matrix.columns.values.tolist():\n",
    "        if (flow_name!=\"Other\" and flow_name!='label'):\n",
    "            flow_str= flow_str+str(cou)+'. '+str(flow_name)+'\\n'\n",
    "            flow_dict[cou]=flow_name\n",
    "            cou+=1\n",
    "    flow_str=flow_str+str(cou)+'. '+'Other'+'\\n'\n",
    "    flow_dict[cou]=flow_name\n",
    "    print('File loaded for %s account: %s'%(account.replace(\"_\",\" \"),infile_name[infile_name.rfind('/')+1:]))\n",
    "    #print('Avilable Flows for thresholds sensitivity analysis:\\n%s'%flow_str)\n",
    "    read_success=True\n",
    "    return eval_flow_matrix,flow_str,flow_dict,read_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def th_analysis(eval_flow_matrix, eval_flow, lower_threshold, upper_threshold):\n",
    "\n",
    "    fully_automated_tp = eval_flow_matrix.loc[(eval_flow_matrix[eval_flow]>=upper_threshold) & \n",
    "                                              (eval_flow_matrix[\"label\"]==eval_flow)].shape[0]\n",
    "\n",
    "    fully_automated_fn = eval_flow_matrix.loc[(eval_flow_matrix[eval_flow]<upper_threshold) & \n",
    "                                              (eval_flow_matrix[\"label\"]==eval_flow)].shape[0]\n",
    "\n",
    "    fully_automated_fp = eval_flow_matrix.loc[(eval_flow_matrix[eval_flow]>=upper_threshold) & \n",
    "                                              (eval_flow_matrix[\"label\"]!=eval_flow)].shape[0]\n",
    "\n",
    "\n",
    "    semi_automated_tp = eval_flow_matrix.loc[(eval_flow_matrix[eval_flow]>=lower_threshold) & \n",
    "                                             (eval_flow_matrix[eval_flow]<upper_threshold) &\n",
    "                                             (eval_flow_matrix[\"label\"]==eval_flow)].shape[0]\n",
    "\n",
    "    semi_automated_fn = eval_flow_matrix.loc[(eval_flow_matrix[eval_flow]<lower_threshold) & \n",
    "                                             (eval_flow_matrix[\"label\"]==eval_flow)].shape[0]\n",
    "\n",
    "    semi_automated_fp = eval_flow_matrix.loc[(eval_flow_matrix[eval_flow]>=lower_threshold) & \n",
    "                                             (eval_flow_matrix[eval_flow]<upper_threshold) &\n",
    "                                             (eval_flow_matrix[\"label\"]!=eval_flow)].shape[0]\n",
    "\n",
    "\n",
    "    print(\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"THRESHOLD SENSITIVITY ANALYSIS FOR %s\\nLower TH-%1.2f; Upper TH-%1.2f\"%(eval_flow.upper(), lower_threshold, upper_threshold))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    overall_tickets=eval_flow_matrix.loc[eval_flow_matrix[\"label\"]==eval_flow].shape[0]\n",
    "    if overall_tickets==0:\n",
    "        return\n",
    "    print(\"Overall %s tickets in labeled data\\t %d (%1.1f%% of all tickets)\\n\"% (eval_flow, overall_tickets,100*overall_tickets/eval_flow_matrix.shape[0]))\n",
    "    correct_reco=int(fully_automated_tp+semi_automated_tp)\n",
    "    print(\"TICKETS IDENTIFIED BY atomIQ Ticketing MACHINE LEARNING\\t %d/%d (%1.1f%% of %d):\"% \n",
    "          (correct_reco,overall_tickets,100*correct_reco/overall_tickets,overall_tickets))\n",
    "    \n",
    "    #print(\"CORRECT RECOMMENDATIONS BY atomIQ TICKETING ON TRAINING DATA:\")\n",
    "    print(\"Tickets identified and routed to full automation\\t %d (%1.1f%% of %d)\"% \n",
    "          (fully_automated_tp,100*fully_automated_tp/overall_tickets,overall_tickets))\n",
    "    print(\"Tickets identified but routed to manual validation\\t %d (%1.1f%% of %d)\\n\"% \n",
    "          (semi_automated_tp,100*semi_automated_tp/overall_tickets,overall_tickets))\n",
    "     \n",
    "    print(\"TICKETS MISCLASSIFIED BY atomIQ TICKETING MACHINE LEARNING:\")\n",
    "    if (fully_automated_tp+fully_automated_fp)>0:\n",
    "        print(\"Tickets misclassified and routed to full automation\\t %d (%1.1f%% of %d+%d)\"% \n",
    "              (fully_automated_fp,100*fully_automated_fp/(fully_automated_fp+fully_automated_tp),fully_automated_fp,fully_automated_tp))\n",
    "    else:\n",
    "        print(\"Tickets misclassified and routed to full automation\\t %d (%1.1f%% of %d+%d)\"% \n",
    "              (fully_automated_fp,0.0,fully_automated_fp,fully_automated_tp))\n",
    "        \n",
    "    if (semi_automated_tp+semi_automated_fp)>0:\n",
    "        print(\"Tickets misclassified but routed to manual validation\\t %d (%1.1f%% of %d+%d)\\n\"% \n",
    "              (semi_automated_fp,100*semi_automated_fp/(semi_automated_fp+semi_automated_tp),semi_automated_fp,semi_automated_tp))\n",
    "    else:\n",
    "        print(\"Tickets misclassified but routed to manual validation\\t %d (%1.1f%% of %d+%d)\\n\"% \n",
    "              (semi_automated_fp,0.0,semi_automated_fp,semi_automated_tp))\n",
    "    #print(\"Fully automated false negatives = %d\\n\"% fully_automated_fn)\n",
    "    \n",
    "    #print(\"%s Tickets that were not labeled as %s by atomIQ Ticketing = %d\\n\"% (eval_flow,eval_flow,semi_automated_fn))\n",
    "    #print(\"Uncorrect recommendation - false negatives = %d\"% int(semi_automated_fn))\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input(input_text,input_type,error_msg,accepted_value_list=None):\n",
    "    success=True\n",
    "    try:\n",
    "        user_input=input(input_text)\n",
    "        casting=str(input_type+'(user_input)')\n",
    "        user_input=eval(casting)\n",
    "        if accepted_value_list:\n",
    "            if user_input not in accepted_value_list:\n",
    "                print(error_msg)\n",
    "                return None, False\n",
    "        return user_input, success\n",
    "    except:\n",
    "        print(error_msg)\n",
    "        return None, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze_flow(eval_flow):\n",
    "    continue_sa=True\n",
    "    while continue_sa:\n",
    "\n",
    "        lower_threshold, success=get_input('Enter lower threshold: ','float','Please enter a number between 0 and 1')\n",
    "        if success:\n",
    "            while (lower_threshold<0 or lower_threshold>1):\n",
    "                print('Please enter a number between 0 and 1')\n",
    "                lower_threshold, success=get_input('Enter lower threshold: ','float','Please enter a number between 0 and 1')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        upper_threshold, success=get_input('Enter upper threshold: ','float','Please enter a number between 0 and 1')\n",
    "        if success:\n",
    "            while (upper_threshold<0 or upper_threshold>1):\n",
    "                print('Please enter a number between 0 and 1')\n",
    "                upper_threshold, success=get_input('Enter upper threshold: ','float','Please enter a number between 0 and 1')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        th_analysis(eval_flow_matrix, eval_flow, lower_threshold, upper_threshold)\n",
    "        \n",
    "        success=False\n",
    "        while not success:\n",
    "            continue_sa, success=get_input('\\nAnalyze another set of thresholds? (Y/N):','str','Please enter Y or N',['Y','N','y','n'])\n",
    "        #continue_sa=get_input(input_text,input_type,error_msg)\n",
    "        if continue_sa.upper()==\"N\": continue_sa=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fetch all active accounts from current configuration folder\n",
    "def active_accounts():\n",
    "    TH_files = glob.glob(Amily_Path+'Archive/Classification/*.txt')\n",
    "    account_list=[]\n",
    "    account_dict={}\n",
    "    for file in TH_files:\n",
    "        account_list.append(file[file.rfind('/')+1:file.rfind('-')-1])\n",
    "    account_list=sorted(list(set(account_list)))\n",
    "    for i, account in enumerate(account_list):\n",
    "        account_dict[str(i+1)]=account\n",
    "    return account_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prints every request that was sent to the Self-Service in the past weeks\n",
    "def fetch_recent_account_files(account, weeks=2):\n",
    "    print('The following requests were received in the past %d weeks for %s:'%(weeks,account))\n",
    "    account_archive_files=glob.glob(Amily_Path+'Archive/Classification/'+'*'+account+'*.txt')\n",
    "    new_requests=0\n",
    "    for path in account_archive_files:\n",
    "        timestamp=os.path.getmtime(path)\n",
    "        if (time.time()-timestamp)<=(60*60*24*7*weeks):\n",
    "            print(time.strftime('%Y-%m-%d %H:%M', time.localtime(timestamp)),'\\t',path[path.rfind('/')+1:])\n",
    "            new_requests+=1\n",
    "    if new_requests==0:\n",
    "        print('No requests were received')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('*********************WELCOME TO atomIQ TICKETING FLOW THRESHOLD SENSITIVITY ANALYSIS********************* ')\n",
    "#account=\"Sprint Nextel Corporation\"\n",
    "#request_id='000000000000209'\n",
    "chosen_account=False\n",
    "print('Avilable accounts for analysis:')\n",
    "account_dict=active_accounts()\n",
    "for key, value in account_dict.items():\n",
    "    print(\"\".join([key,\". \",value]))\n",
    "while not chosen_account:\n",
    "    account, chosen_account=get_input(''.join(['Please choose account number [1-',str(len(account_dict)),']: ']),\n",
    "                               'int',''.join(['Please enter a number between 1 and ',str(len(account_dict))])\n",
    "                                ,np.arange(len(account_dict)+1).tolist())\n",
    "account=account_dict[str(account)]\n",
    "print('Chosen account:',account)\n",
    "    \n",
    "read_success=False\n",
    "while not read_success:\n",
    "    #account=input('Enter account: ')\n",
    "    fetch_recent_account_files(account)\n",
    "    request_id=input('Enter training session request ID: ')\n",
    "    eval_flow_matrix,flow_str,flow_dict,read_success=read_data(account, request_id)\n",
    "    \n",
    "    if not read_success:\n",
    "        continue_feedback_success=False\n",
    "        while not continue_feedback_success:\n",
    "            continue_feedback,continue_feedback_success=get_input('\\nDo you wish to continue? (Y/N):','str','Please enter Y or N',['Y','N','y','n']) \n",
    "        if continue_feedback.upper()=='N': break\n",
    "            \n",
    "if read_success:\n",
    "    \n",
    "    flow_count=len(flow_dict)\n",
    "    evaluate_flow=True\n",
    "\n",
    "    while evaluate_flow:\n",
    "        print(\"\".join(['\\nFlows avilable for analysis:\\n',flow_str]))\n",
    "        success=False\n",
    "        while not success:\n",
    "            eval_flow_ind, success=get_input(''.join(['Please choose flow number [1-',str(flow_count),']: ']),\n",
    "                               'int',''.join(['Please enter a number between 1 and ',str(flow_count)])\n",
    "                                ,(np.arange(flow_count)+1).tolist())\n",
    "            if success:\n",
    "                eval_flow=flow_dict[eval_flow_ind]\n",
    "                print('\\nChosen flow: ',eval_flow)\n",
    "\n",
    "        analyze_flow(eval_flow)\n",
    "\n",
    "        success_sa=False\n",
    "        while not success_sa:\n",
    "            continue_sa, success_sa=get_input('\\nAnalyze another flow? (Y/N):','str'\n",
    "                                              ,'Please enter Y or N',['Y','N','y','n'])\n",
    "        if continue_sa.upper()==\"N\": evaluate_flow=False\n",
    "    \n",
    "print('****************************************THANK YOU AND GOODBYE :-)**************************************** ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
